{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omrdatasettools.Downloader import Downloader\n",
    "from omrdatasettools.OmrDataset import OmrDataset\n",
    "from omrdatasettools.MuscimaPlusPlusSymbolImageGenerator import MuscimaPlusPlusSymbolImageGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloader module is used to extract the raw information about the datasets into the ./data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.download_and_extract_dataset(OmrDataset.MuscimaPlusPlus_V2, \"data/muscima_pp_v2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated raw files are then used to draw the images of the dataset on canvases and store them in different folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscima_generator = MuscimaPlusPlusSymbolImageGenerator()\n",
    "muscima_generator.extract_and_render_all_symbol_masks(\"./data/muscima_pp_v2/\", \"./data/muscima_pp_v2_symbols/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the models, the images first have to be resized to be a standard size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's find out what the max height and width is, and use those values to resize all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\data\\\\muscima_pp_v2_symbols\\\\arpeggio', '.\\\\data\\\\muscima_pp_v2_symbols\\\\articulationAccent', '.\\\\data\\\\muscima_pp_v2_symbols\\\\articulationStaccato', '.\\\\data\\\\muscima_pp_v2_symbols\\\\articulationTenuto', '.\\\\data\\\\muscima_pp_v2_symbols\\\\augmentationDot', '.\\\\data\\\\muscima_pp_v2_symbols\\\\breathMark', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalA', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalC', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalE', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalF', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalL', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalM', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalP', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalR', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalS', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalT', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterCapitalV', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterDot', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterOther', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallA', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallB', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallC', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallD', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallE', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallF', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallG', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallI', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallJ', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallL', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallM', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallN', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallO', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallP', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallR', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallS', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallT', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallU', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallV', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallX', '.\\\\data\\\\muscima_pp_v2_symbols\\\\characterSmallZ', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dottedHorizontalSpanner', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicCrescendoHairpin', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicDiminuendoHairpin', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicLetterF', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicLetterM', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicLetterP', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicLetterS', '.\\\\data\\\\muscima_pp_v2_symbols\\\\dynamicsText', '.\\\\data\\\\muscima_pp_v2_symbols\\\\fermataAbove', '.\\\\data\\\\muscima_pp_v2_symbols\\\\glissando', '.\\\\data\\\\muscima_pp_v2_symbols\\\\graceNoteAcciaccatura', '.\\\\data\\\\muscima_pp_v2_symbols\\\\instrumentSpecific', '.\\\\data\\\\muscima_pp_v2_symbols\\\\keySignature', '.\\\\data\\\\muscima_pp_v2_symbols\\\\multipleNoteTremolo', '.\\\\data\\\\muscima_pp_v2_symbols\\\\noteheadFull', '.\\\\data\\\\muscima_pp_v2_symbols\\\\noteheadFullSmall', '.\\\\data\\\\muscima_pp_v2_symbols\\\\noteheadHalf', '.\\\\data\\\\muscima_pp_v2_symbols\\\\noteheadWhole', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral0', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral1', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral2', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral3', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral4', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral5', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral6', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral7', '.\\\\data\\\\muscima_pp_v2_symbols\\\\numeral8', '.\\\\data\\\\muscima_pp_v2_symbols\\\\ornament', '.\\\\data\\\\muscima_pp_v2_symbols\\\\ornamentTrill', '.\\\\data\\\\muscima_pp_v2_symbols\\\\otherNumericSign', '.\\\\data\\\\muscima_pp_v2_symbols\\\\otherText', '.\\\\data\\\\muscima_pp_v2_symbols\\\\repeat', '.\\\\data\\\\muscima_pp_v2_symbols\\\\repeat1Bar', '.\\\\data\\\\muscima_pp_v2_symbols\\\\tempoText', '.\\\\data\\\\muscima_pp_v2_symbols\\\\textCresc', '.\\\\data\\\\muscima_pp_v2_symbols\\\\textDim', '.\\\\data\\\\muscima_pp_v2_symbols\\\\textPed', '.\\\\data\\\\muscima_pp_v2_symbols\\\\textRall', '.\\\\data\\\\muscima_pp_v2_symbols\\\\timeSigCommon', '.\\\\data\\\\muscima_pp_v2_symbols\\\\timeSignature', '.\\\\data\\\\muscima_pp_v2_symbols\\\\wiggleTrill']\n",
      "Maximum width: 1153 Maximum height: 861\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the path to the directory containing the images\n",
    "directory = '.\\\\data\\\\muscima_pp_v2_symbols'\n",
    "\n",
    "# Get the list of files and directories in the directory\n",
    "files_and_dirs = [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "print(files_and_dirs)\n",
    "max_width, max_height = 0, 0\n",
    "for file in files_and_dirs:\n",
    "    for inner_file in os.listdir(file):\n",
    "        inner_file_path = os.path.join(file, inner_file)\n",
    "        if os.path.isfile(inner_file_path):\n",
    "            img = Image.open(inner_file_path)\n",
    "            if (max_height  == 0) or (max_height == 0):\n",
    "                max_width, max_height = img.size\n",
    "            # Determine the maximum width and height of the image\n",
    "            if img.size[0] > max_width:\n",
    "                max_width = img.size[0]\n",
    "            if img.size[1] > max_height:\n",
    "                max_height = img.size[1]\n",
    "            # Close the image without saving any changes\n",
    "            img.close()\n",
    "\n",
    "print(\"Maximum width:\", max_width, \"Maximum height:\", max_height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the maximum width is 1153, and the maximum height is 861. Now we have to resize all images in the dataset to this size to normalize the dataset for use in a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Each image will be resized to the maximum width and height\n",
    "# first, create a new image of the desired size and color (white) for padding\n",
    "blank_image = np.full((max_height, max_width, 3), (255, 255, 255), dtype=np.uint8)\n",
    "\n",
    "# Get the list of files and directories in the directory\n",
    "files_and_dirs = [os.path.join(\".\\\\data\", \"muscima_pp_v2_symbols\", file) for file in os.listdir(directory)]\n",
    "\n",
    "for file in files_and_dirs:\n",
    "       for inner_file in os.listdir(file):\n",
    "              inner_file_path = os.path.join(file, inner_file)\n",
    "              if os.path.isfile(inner_file_path):\n",
    "                     img = cv2.imread(inner_file_path)\n",
    "                     old_image_height, old_image_width, channels = img.shape\n",
    "                     temp = blank_image.copy()\n",
    "                     # compute center offset\n",
    "                     x_center = (max_width - old_image_width) // 2\n",
    "                     y_center = (max_height - old_image_height) // 2\n",
    "                     # copy img image into center of result image\n",
    "                     temp[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = img\n",
    "                     # save result\n",
    "                     cv2.imwrite(inner_file_path, temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is normalised, it is time to split the dataset and train the Convolutional Neural Network (CNN) and the Support Vector Machine (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split the data into training, test and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset directory\n",
    "data_dir = '.\\\\data\\\\muscima_pp_v2_symbols'\n",
    "\n",
    "# Define the size of your input images\n",
    "input_size = (1153, 861)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = len(os.listdir(data_dir))\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% of the data will be used for validation\n",
    ")\n",
    "\n",
    "# Load and split the data into train, validation, and test sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Specify training subset\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify validation subset\n",
    ")\n",
    "\n",
    "# Split the validation set further into validation and test sets\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    validation_generator.samples,\n",
    "    validation_generator.labels,\n",
    "    test_size=0.5,  # 50% of validation data becomes the test set\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create separate generators for validation and test sets\n",
    "validation_generator = datagen.flow(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build and compile the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1153, 861, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation, we can train the model using the test and validation sets. These results are then stored in cnn_history. After this, the model is evaluated using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "cnn_history = cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "#Evaluate the model using the test set\n",
    "test_results = cnn.evaluate(test_generator)\n",
    "print(\"Test loss:\", test_results[0])\n",
    "print(\"Test accuracy:\", test_results[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the model can be saved for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_test1.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use matplotlib to visualise the training progress by using the \"cnn_history\" variable to plot the training and validation accuracy and loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omrdatasettools.Downloader import Downloader\n",
    "from omrdatasettools.OmrDataset import OmrDataset\n",
    "from omrdatasettools.MuscimaPlusPlusSymbolImageGenerator import MuscimaPlusPlusSymbolImageGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloader module is used to extract the raw information about the datasets into the ./data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.download_and_extract_dataset(OmrDataset.MuscimaPlusPlus_V2, \"data/muscima_pp_v2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated raw files are then used to draw the images of the dataset on canvases and store them in different folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscima_generator = MuscimaPlusPlusSymbolImageGenerator()\n",
    "muscima_generator.extract_and_render_all_symbol_masks(\"./data/muscima_pp_v2/\", \"./data/muscima_pp_v2_symbols/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the models, the images first have to be resized to be a standard size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's find out what the max height and width is, and use those values to resize all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with a width of 1153 pixels:\n",
      ".\\data\\muscima_pp_v2_symbols\\repeat\\MUSCIMA-pp_2.0___CVC-MUSCIMA_W-32_N-12_D-ideal___580.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the root folder containing your images\n",
    "root_folder = \".\\\\data\\\\muscima_pp_v2_symbols\"\n",
    "\n",
    "# Desired width to search for\n",
    "desired_width = 861\n",
    "\n",
    "# Initialize a list to store image file paths that match the desired width\n",
    "matching_images = []\n",
    "\n",
    "# Iterate through all subfolders and their images\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\")):\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "            _, height = image.size\n",
    "            if height == desired_width:\n",
    "                matching_images.append(image_path)\n",
    "\n",
    "# Print the paths of images with the desired width\n",
    "if matching_images:\n",
    "    print(\"Images with a width of 1153 pixels:\")\n",
    "    for image_path in matching_images:\n",
    "        print(image_path)\n",
    "else:\n",
    "    print(\"No images with a width of 1153 pixels found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images in subfolders have been resized to the maximum width and height.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the root folder containing subfolders with images\n",
    "root_folder = \".\\\\data\\\\muscima_pp_v2_symbols\"\n",
    "\n",
    "# Initialize variables to store maximum width and height\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "\n",
    "# Iterate through all subfolders and their images to find maximum width and height\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\")):\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "            width, height = image.size\n",
    "            max_width = max(max_width, width)\n",
    "            max_height = max(max_height, height)\n",
    "\n",
    "# Iterate through all subfolders and their images again and pad them\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\")):\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Calculate padding dimensions\n",
    "            padding_width = max_width - image.width\n",
    "            padding_height = max_height - image.height\n",
    "            \n",
    "            # Create a new image with white padding\n",
    "            padded_image = Image.new(\"RGB\", (max_width, max_height), (255, 255, 255))\n",
    "            \n",
    "            # Calculate the position to paste the original image (centered)\n",
    "            paste_x = padding_width // 2\n",
    "            paste_y = padding_height // 2\n",
    "            \n",
    "            # Paste the original image onto the padded image\n",
    "            padded_image.paste(image, (paste_x, paste_y))\n",
    "            \n",
    "            # Save the padded image, overwriting the original\n",
    "            padded_image.save(image_path)\n",
    "\n",
    "print(\"All images in subfolders have been resized to the maximum width and height.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the images are quite large. To aid in training, we can reduce the size by 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images in subfolders have been resized to 50% of their size while preserving aspect ratio and stored in corresponding output subfolders.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the root folder containing the padded images\n",
    "root_folder = \".\\\\data\\\\muscima_pp_v2_symbols\"\n",
    "\n",
    "# Initialize the output folder\n",
    "output_root_folder = \".\\\\data\\\\muscima_pp_v2_symbols_resized\"\n",
    "\n",
    "# Create the output root folder if it doesn't exist\n",
    "if not os.path.exists(output_root_folder):\n",
    "    os.makedirs(output_root_folder)\n",
    "\n",
    "# Specify the scale factor for resizing (50% in this case)\n",
    "scale_factor = 0.5\n",
    "\n",
    "# Iterate through all subfolders and their images\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    # Create the corresponding subfolder structure in the output directory\n",
    "    relative_folder = os.path.relpath(foldername, root_folder)\n",
    "    output_folder = os.path.join(output_root_folder, relative_folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\")):\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Calculate the new dimensions while preserving aspect ratio\n",
    "            width, height = image.size\n",
    "            new_width = int(width * scale_factor)\n",
    "            new_height = int(height * scale_factor)\n",
    "\n",
    "            # Resize the image\n",
    "            resized_image = image.resize((new_width, new_height))\n",
    "\n",
    "            # Save the resized image to the corresponding output subfolder\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            resized_image.save(output_path)\n",
    "\n",
    "print(\"All images in subfolders have been resized to 50% of their size while preserving aspect ratio and stored in corresponding output subfolders.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to supplement the dataset by rotating the images 10 degrees and -10 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_folder = \".\\\\data\\\\muscima_pp_v2_symbols_resized\"\n",
    "rotate_degrees = [10, -10]\n",
    "\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\")):\n",
    "            # Get the full image path\n",
    "            image_path = os.path.join(foldername, filename)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Get image dimensions\n",
    "            height, width = image.size\n",
    "\n",
    "            for degree in rotate_degrees:\n",
    "                new_image = image.rotate(degree, fillcolor=(255, 255, 255))\n",
    "\n",
    "                # Get the original file extension\n",
    "                file_extension = os.path.splitext(filename)[-1]\n",
    "\n",
    "                # Save the rotated image with a new filename in the output folder\n",
    "                new_filename = filename.replace(file_extension, f\"_rotated{degree}{file_extension}\")\n",
    "                new_image_path = os.path.join(foldername, new_filename)\n",
    "                new_image.save(new_image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is normalised, it is time to split the dataset and train the Convolutional Neural Network (CNN) and the Support Vector Machine (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split the data into training, test and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 75\n",
      "Found 31242 images belonging to 75 classes.\n",
      "Found 7770 images belonging to 75 classes.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "data_dir = '.\\\\data\\\\muscima_pp_v2_symbols_resized'\n",
    "\n",
    "# Define the size of your input images\n",
    "input_size = (344, 126)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = len(os.listdir(data_dir))\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% of the data will be used for validation\n",
    ")\n",
    "\n",
    "# Load and split the data into train, validation, and test sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Specify training subset\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify validation subset\n",
    ")\n",
    "\n",
    "validation_data = []\n",
    "validation_labels = []\n",
    "\n",
    "# Collect batches in smaller groups and resize images\n",
    "for i in range(len(validation_generator)):\n",
    "    batch_data, batch_labels = validation_generator[i]\n",
    "    \n",
    "    # Ensure the data type and range are appropriate\n",
    "    batch_data = (batch_data * 255).astype(np.uint8)  # Normalize to [0, 255] and convert to uint8\n",
    "        \n",
    "    validation_data.extend(batch_data)\n",
    "    validation_labels.extend(batch_labels)\n",
    "\n",
    "# Convert the lists to arrays\n",
    "x_val = np.array(validation_data)\n",
    "y_val = np.array(validation_labels)\n",
    "\n",
    "# Now, you can split x_val and y_val into validation and test sets\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    test_size=0.5,  # 50% of validation data becomes the test set\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create separate generators for validation and test sets\n",
    "validation_generator = datagen.flow(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build and compile the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(344, 126, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(75, activation='softmax') \n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation, we can train the model using the test and validation sets. These results are then stored in cnn_history. After this, the model is evaluated using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "977/977 [==============================] - 768s 783ms/step - loss: 2.6076 - accuracy: 0.2679 - val_loss: 3.1374 - val_accuracy: 0.2386\n",
      "Epoch 2/10\n",
      "977/977 [==============================] - 750s 768ms/step - loss: 2.0886 - accuracy: 0.3426 - val_loss: 2.7386 - val_accuracy: 0.3104\n",
      "Epoch 3/10\n",
      "977/977 [==============================] - 740s 758ms/step - loss: 1.9337 - accuracy: 0.3700 - val_loss: 2.7992 - val_accuracy: 0.3300\n",
      "Epoch 4/10\n",
      "276/977 [=======>......................] - ETA: 8:34 - loss: 1.8570 - accuracy: 0.3886"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "cnn_history = cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "#Evaluate the model using the test set\n",
    "test_results = cnn.evaluate(test_generator)\n",
    "print(\"Test loss:\", test_results[0])\n",
    "print(\"Test accuracy:\", test_results[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the model can be saved for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_test1.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use matplotlib to visualise the training progress by using the \"cnn_history\" variable to plot the training and validation accuracy and loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
